# MHA2MLA 渐进式压缩：最小可行性验证实验报告

## 1. 实验背景

### 1.1 MHA2MLA 简介

MHA2MLA（Multi-Head Attention to Multi-Head Latent Attention）是一种将标准 Transformer 模型中的多头注意力机制转换为 DeepSeek 提出的多头潜在注意力机制的后训练压缩方法，出自论文 *"Towards Economical Inference: Enabling DeepSeek's Multi-Head Latent Attention in Any Transformer-based LLMs"*（arXiv:2502.14837）。

标准 MHA 中，每个注意力头独立维护全秩的 Key 和 Value 投影矩阵，推理时需要缓存完整的 KV Cache，内存开销随序列长度线性增长。MLA 的核心思想是对 KV 投影进行**低秩分解**，将原始的 $W_K$ 和 $W_V$ 分解为下投影矩阵 $W_{down}$ 和上投影矩阵 $W_{up}$ 的乘积：

$$W_K \approx W_{up\_k} \cdot W_{down}, \quad W_V \approx W_{up\_v} \cdot W_{down}$$

推理时只需缓存低维的潜在表示 $c = x \cdot W_{down}^T$，而非完整的 K、V 向量，从而减少 KV Cache 的内存占用。需要说明的是，该压缩主要目标是**减少推理时 KV Cache 的内存占用**，而非减小模型文件体积。

### 1.2 关键技术组件

**Partial RoPE（部分旋转位置编码）**：MLA 将 Key 分为两部分——携带位置信息的 $K_r$（应用 RoPE）和不携带位置信息的 $K_c$（从压缩潜在表示恢复）。本实验采用 **2-norm** 策略选择 RoPE 维度，即根据 QK 权重矩阵各维度的 2-范数大小排序，选取最重要的维度应用 RoPE。每个头保留 `rope_dim_for_mla=4` 个 RoPE 维度。

**SVD 低秩初始化**：采用 **joint** 方法，将 $K_c$ 和 $V$ 的权重矩阵拼接后统一做 SVD 分解，共享同一个下投影矩阵 $W_{down\_kv}$：

$$[W_{K_c}; W_V] \approx [W_{up\_k}; W_{up\_v}] \cdot W_{down\_kv}$$

这样在推理时只需计算一次下投影，进一步减少计算量。

### 1.3 渐进式压缩的动机

原始 MHA2MLA 方法直接将模型压缩到目标低秩，然后进行恢复性训练。当目标秩较低时，一步到位的压缩会造成较大的信息损失，模型需要更多的训练步数才能恢复性能。

**渐进式压缩**的核心思想是：不一步压缩到目标秩，而是分多个阶段逐步降低秩，每个阶段进行一定步数的训练让模型适应当前压缩程度，然后再进一步压缩。这类似于课程学习（Curriculum Learning）的思路——先让模型学会在较容易的条件下（高秩，信息损失小）运行，再逐步过渡到更困难的条件（低秩，信息损失大）。

## 2. 实验设置

### 2.1 基础模型

- **模型**：SmolLM-135M（HuggingFaceTB/SmolLM-135M）
- **参数量**：135M
- **原始模型大小**：256.57 MB
- **压缩后模型大小**：245.61 MB

### 2.2 训练配置

| 配置项 | 原始压缩 | 渐进式压缩 |
|--------|----------|------------|
| 压缩秩 | 固定 rank=8 | 16 → 12 → 8 |
| 总训练步数 | 3000 | 3000（1000 × 3 阶段） |
| 每阶段 Warmup | — | 100 / 50 / 50 |
| Partial RoPE | 2-norm, dim=4 | 2-norm, dim=4 |
| SVD 方法 | joint | joint |
| Batch size | 4 × 4 GPU × 32 梯度累积 = 512 | 同左 |
| 序列长度 | 2048 | 2048 |
| 学习率 | 1e-4 | 1e-4 |
| 优化器 | AdamW | AdamW（阶段间重置） |
| 数据集 | cosmopedia-v2 | cosmopedia-v2 |
| 精度 | bfloat16 | bfloat16 |
| 硬件 | 4 × RTX 3090 | 4 × RTX 3090 |

### 2.3 渐进式压缩流程

```
阶段 0 (Step 0-1000)      阶段 1 (Step 1000-2000)    阶段 2 (Step 2000-3000)
┌─────────────────────┐   ┌─────────────────────┐   ┌─────────────────────┐
│  rank = 16          │   │  rank = 12          │   │  rank = 8           │
│  Warmup: 100 steps  │──→│  Warmup: 50 steps   │──→│  Warmup: 50 steps   │
│  Train: 1000 steps  │   │  Train: 1000 steps  │   │  Train: 1000 steps  │
└─────────────────────┘   └─────────────────────┘   └─────────────────────┘
                        ↑                         ↑
                   重建权重矩阵               重建权重矩阵
                   SVD 重分解                 SVD 重分解
                   重置优化器                 重置优化器
```

阶段切换时的具体操作：
1. **重建权重矩阵**：从当前 LowRankKVLinear 中恢复完整的 K、V 权重矩阵：$W_K = W_{up\_k} \cdot W_{down\_kv}$，$W_V = W_{up\_v} \cdot W_{down\_kv}$
2. **SVD 重分解**：将恢复的完整权重矩阵以新的（更低的）秩重新进行 SVD 分解
3. **重置优化器**：创建新的优化器和学习率调度器，避免旧的动量状态干扰新阶段的训练

### 2.4 步数对应关系

渐进式压缩的阶段 2（最终 rank=8）从全局第 2000 步开始训练。因此：

| 渐进式阶段 2 局部步数 | 全局总步数 | 对应原始压缩步数 |
|----------------------|-----------|----------------|
| 100 | 2100 | 2100 |
| 400 | 2400 | 2400 |
| 700 | 2700 | 2700 |
| 1000 (final) | 3000 | 3000 |

### 2.5 评估设置

- **评估框架**：LightEval
- **评估指标**：acc_norm（归一化准确率）
- **评估基准**：
  - **ARC-Easy**：AI2 推理挑战（简单集），2376 道科学推理选择题
  - **HellaSwag**：常识推理补全任务，10042 道题目
  - **PIQA**：物理直觉问答，1838 道题目

注：本实验仅包含判别式任务评估，未涵盖生成式任务（如文本生成质量、困惑度等）。

## 3. 实验结果

### 3.1 总览

| 模型 | ARC-Easy | HellaSwag | PIQA | 平均 |
|------|----------|-----------|------|------|
| Baseline（原始 SmolLM-135M） | 0.5619 | 0.4115 | 0.6806 | 0.5513 |
| 原始压缩 @ 2100 步 | 0.4285 | 0.2884 | 0.6197 | 0.4455 |
| 原始压缩 @ 2400 步 | 0.4217 | 0.2909 | 0.6159 | 0.4428 |
| 原始压缩 @ 2700 步 | 0.4272 | 0.2937 | 0.6257 | 0.4488 |
| 原始压缩 @ 3000 步 | 0.4339 | 0.2977 | 0.6279 | 0.4532 |
| 渐进压缩 @ 2100 步 (stage2-100) | 0.4268 | 0.2904 | 0.6023 | 0.4398 |
| 渐进压缩 @ 2400 步 (stage2-400) | 0.4390 | 0.2976 | 0.6126 | 0.4497 |
| 渐进压缩 @ 2700 步 (stage2-700) | 0.4423 | 0.2983 | 0.6186 | 0.4531 |
| 渐进压缩 @ 3000 步 (final) | 0.4470 | 0.3012 | 0.6202 | 0.4561 |

### 3.2 相同总步数下的对比

| 总步数 | 原始压缩（avg） | 渐进压缩（avg） | 差值（渐进 - 原始） |
|--------|----------------|----------------|-------------------|
| 2100 | 0.4455 | 0.4398 | -0.0057 |
| 2400 | 0.4428 | 0.4497 | +0.0069 |
| 2700 | 0.4488 | 0.4531 | +0.0043 |
| 3000 | 0.4532 | 0.4561 | +0.0029 |

### 3.3 各基准详细对比（3000 步最终结果）

| 基准 | Baseline | 原始压缩 | 渐进压缩 | 压缩损失（原始） | 压缩损失（渐进） |
|------|----------|---------|---------|----------------|----------------|
| ARC-Easy | 0.5619 | 0.4339 | 0.4470 | -0.1280 (22.8%) | -0.1149 (20.5%) |
| HellaSwag | 0.4115 | 0.2977 | 0.3012 | -0.1138 (27.7%) | -0.1103 (26.8%) |
| PIQA | 0.6806 | 0.6279 | 0.6202 | -0.0527 (7.7%) | -0.0604 (8.9%) |
| 平均 | 0.5513 | 0.4532 | 0.4561 | -0.0981 (17.8%) | -0.0952 (17.3%) |

## 4. 结果分析

### 4.1 初步观察

从训练过程来看，渐进式压缩呈现出一定的**后期追赶**趋势：

- **2100 步时**（渐进式刚进入 rank=8 阶段 100 步）：渐进式（0.4398）略低于原始压缩（0.4455）。这是预期中的结果，因为渐进式模型刚从 rank=12 重新压缩到 rank=8，经历了一次信息损失，还处于恢复初期。
- **2400 步时**：渐进式（0.4497）开始超过原始压缩（0.4428）。
- **3000 步时**：渐进式（0.4561）略高于原始压缩（0.4532）。

在 3 个评估基准中，渐进式在 ARC-Easy 和 HellaSwag 上略高于原始压缩，但在 PIQA 上略低。各基准上的差异均较小，尚在正常波动范围内。

### 4.2 与 Baseline 的性能差距

两种压缩方法相对于未压缩的 Baseline 均有较大的性能下降（约 17-18%）。可能的原因包括：

1. **压缩比较激进**：最终 rank=8 对于 135M 参数的小模型而言是较低的秩，每个注意力头的 KV 维度从原始的 64 压缩到了 8（压缩比 8:1）。
2. **模型容量有限**：SmolLM-135M 本身参数量较小，冗余空间有限，低秩压缩对其影响比大模型可能更为显著。
3. **训练步数有限**：3000 步的恢复训练对于完全恢复性能可能不够充分。

### 4.3 关于渐进式压缩的可能优势机理

如果渐进式压缩确实有效，其原因可能包括：

1. **信息保留的梯度过渡**：高秩阶段保留了更多的原始信息，模型先在信息较完整的条件下优化注意力权重，这些优化后的权重在重分解时可能成为更好的初始化。
2. **SVD 重分解的质量**：经过训练优化的权重矩阵，其奇异值分布可能更集中于前几个主成分，使得低秩近似的信息损失更小。
3. **优化器重置的正则化效果**：每个阶段重置优化器，避免了旧动量对新结构的干扰。

但以上均为推测性解释，需要进一步实验验证。

## 5. 实验局限性

本实验作为最小可行性验证（Minimum Viable Experiment），存在以下明显局限：

1. **模型规模过小**：SmolLM-135M 仅 135M 参数，不能代表实际应用中的 7B 及以上规模模型。小模型的冗余度低，压缩行为可能与大模型有本质差异。
2. **仅单次实验**：所有结果均来自单次运行，缺乏多次实验的统计置信度。观察到的性能差异（~0.3%）可能在随机种子变化后不再成立。
3. **评估方式单一**：仅使用了 3 个判别式基准（多选题形式），未包含生成式任务评估（如困惑度、文本生成质量、对话能力等），不能全面反映压缩对模型能力的影响。
4. **训练步数不足**：3000 步的训练规模较小，无法观察更长训练下两种方法的收敛行为差异。
5. **超参数未充分搜索**：渐进式压缩的阶段数、秩递减策略、每阶段步数分配等均未经系统调优。
6. **单一压缩配置**：仅测试了 rank 16→12→8 一种渐进路径，未与其他路径（如 16→8、32→16→8 等）进行对比。

## 6. 结论与展望

### 6.1 初步结论

本实验在 SmolLM-135M 上对 MHA2MLA 渐进式压缩策略进行了初步验证。在当前实验条件下，渐进式压缩（0.4561）相比原始一步压缩（0.4532）在平均性能上有微小的提升（+0.29%）。该结果表明渐进式压缩作为一种改进方向**具有一定的可行性**，但由于实验规模和次数的限制，尚不能得出确定性结论。

### 6.2 后续工作

为进一步验证和完善该方法，建议开展以下工作：

1. **扩大模型规模**：在 7B 或更大规模的模型（如 Llama-2-7B、Qwen-7B）上重复实验，观察渐进式压缩的效果是否随模型规模增大而更加显著。
2. **增加训练步数**：使用更多的训练步数，观察两种方法在充分训练后的最终性能差距。
3. **多次重复实验**：使用不同随机种子进行多次实验，计算均值和标准差，确认结果的统计显著性。
4. **补充生成式评估**：加入困惑度（PPL）、文本生成质量等评估指标，更全面地衡量压缩对模型能力的影响。
5. **探索更多渐进策略**：尝试不同的阶段数、秩递减曲线和步数分配方案，寻找更优的渐进压缩配置。
